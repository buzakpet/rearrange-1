INTRO TO MODULE 5: TESTING IN PYTHON
Over the last weeks, we've been learning what we can do with python. from managing files, processing text, starting system proccesses etc. Up until now, whenever we wrote python code, in the interpreter or in our scripts, we've been testing it by manually running it and seeing if it did what we wanted it to do. In this module we will create automatic test that will perform this kids of checks for us. This will let us focus on just writing the code instead of checking if any changes we made to it breaks the previous functionality. It will also help us verify that features we add do what we expect in lots of possible ways. 
We will also learn the different types of testing that are out there, and how we can use them to make our code more reliable. 
Finally we will learn how to handle errors and exception in python code, how to trap those errors so the dont stop programs from completing, how to raise errors when neccessary and how to test that our code generates the right kinds of errors. 

WHAT IS TESTING?
When operations become more complex, when using loops, conditionals, calling more and more functions, its harder to be confident that the code will do what its supposed. This is where software testing comes into play.
Software Testing: The process of evaluating computer code to determine whethter or not it does what you expect it to do.
When we test a piece of software, we want to see the errors and defects, and where things go wrong. We want to be sure that the program really does what we want or expect it to do.
Scripts and programs can fail in all sorts of strange ways, especially when the become more complicated.
In all but the simpe programs, its close to impossible to test for everything that can go wrong even if it means that a certain number of bugs might exist in your script without realizing it, don't worry. Writing test can help elimate a whole bunch of bugs, helping to improve the reliability flexibility of automation.
***Test can help make good become great***

MANUAL TESTING AND AUTOMATED TESTING
The most basic way to test our script is to run it with various parameters and see if it does what is expected. Running a script with various command-line arguments is an example of manual testing. Using the interpreter to try our code before puting it in the script is another form of manual testing. 
Formal Software testing takes this process a litle bit further, Codifying test into its own software and code which will verify that our programs and code do what is expected of them. This is called automatic testing. THE GOAL OF AUTOMATIC TESTING IS TO AUTOMATE THE PROCESS OF CHECKING IF THE RETURN VALUE MATCHES THE EXPECTATIONS. Instead of we the humans running the program time and time again with different parameters, we let the program do this for us.
When we are writing our code, we want to check that it does what its supposed to do for a lot of different values. We want to verify that it behaves the way we expect it to with many possible values called TEST CASES.
Say we are writing a script that updates a list of email addresses to use a new domain, similar to the one we wrote a while back, we want to test when our list of emails has 1 element, 2 elements, 3 elements or 10 elements. we want to test if our new domain is 1 character long or 2 characters long or even an empty string. We also want to test what happens if the list contains only emails that need to be updated, only emails that don't need to be updted or a mix of them.
The list of things we need to check can increase very fast. 
The more test cases we include in our test, the more better tested our code is, and the more gauranteed that our code does what we expect it to do. 

UNIT TESTING
There are a lot of different type of test we can write to perform automatic testing, but the most common is called the unit test
Unit tests: Used to verify that small, isolated parts of a program are correct.
***Unit test are usually writen ALONGSIDE the code to test individual pieces or units like functions or methods. It helps assures the developer that that piece of code does what it is meant to do. 
An important aspect of a unit test is isolation. Unit test should only test the unit of code it targets, the function or method being tested.
This ensures that any success or failures is caused by the behaviour of the unit in question and does not result from some external factor like, the network being down or the database being unresponsive. 
In other words, when testing a function or method we want to be sure that we are checking the code in that function or method behaves correctly. We don't want our test to fail for external reasons. 
On a related note, our test should never modify the production enviroment. This is a live enviroment that runs the software that users interact with. 
When developing test, if, for any reason, we need to interact with another software, we normaly do that in a *test enviroment* were we have control over how the code behaves.
How do we go about the unit test? It boils down to a certain pattern. Given a known input, does the output match our expectations? 
To illustrate let us try it on our code that rearranges lastname, firstname

cat rearrange.py

How do we test that it works the way we expect it to? Lets start by manual validation. We check this by importing the function in our interpreter. We do this using the key word 'from'
Let us first create a rearrange.py module

#!/usr/bin/env python3

import re

def rearrange_name(name):
    result = re.search(r"^([\w .]*), ([\w .]*)$", name)
    return "{} {}".format(result[2], result[1])

Then we import the rearrange_name function from the rearrange module.

from rearrange import rearrange_name

By importing the function rearrange_name in this way, we dont have to suffix the 'rearrange_name' function with the module name 'rearrange' whenever we want to call it. like this:

rearrange_name('Lovelace, Ada')

The result is what we expected given the input we provided, and so it has passed this particular unit test.

WRITING UNIT TEST IN PYTHON

How can we automate the validation of the function rearrange_name?
Lets create the unit test for the rearrange_name function from our previous example. 
THE CODE FOR AUTOMATIC TESTING ARE USUALLY WRITEN ALONGSIDE THE CODE WE WANT TO TEST. THIS MEANS IN PRACTICE CREATING A SEPERATE PYTHON FILE WITH THE TEST. 
The convention is to call the script with the same name of the module that its testing and appending the suffix '_test'. So for our rearrange module, we would create the rearrange_test.py file.

atom rearrange_test.py

We will test the rearrange_name function with the rearrange module. So we will import that function in the interpreter the way we did before.

rearrange_test.py
#!/usr/bin/env python3

from rearrange import rearrange_name
import unittest

class TestRearrange(unittest.TestCase):
    def test_basic(self):
        testcase = "Lovelace, Ada"
        expected = "Ada Lovelace"
        self.assertEqual(rearrange_name(testcase), expected)

unittest.main()



To help write the test, Python provides a module called 'unittest'. This module includes a number of classes and methods that help us easily create unittest for our code.
The next thing we do is import the unittest module needed for testing. The unittest module provides a TestCase class, with the a bunch of testing methods ready to use. TO ACCESS THIS FUNCTIONALITY WE CREATE OUR  OWN CLASS THAT INHERITS FROM TESTCASE, THUS INHERITING ALL THOSE TESTING METHODS.
So we are going to write our own TestRearrange class that inherits from TestCase. To do this, we need to include the class we are going to inherit from in the parenthesis. We called our test class, TestRearrange which inherits from TestCase in the unittest module.
ANY METHODS WE DEFINE IN OUR TESTREARRANGE CLASS THAT START WITH THE PREFIX TEST WILL AUTOMATICALLY BECOME TEST THAT WE RUN WITH THE TESTING FRAMEWORK. 
With the method called test_basic(self):, we kickoff by defining what our expected input and output should be. We then use the assertEqual method provided by the TestCase class we inherited from to verify that what we got is exactly what was expected. In other words, the assertEqual is basically saying that both my arguments are equal. If that statements returns a True, then that test passes. If it returns False, the the test fails and an error is printed to the screen when the test is run.
So how do we run this unit test? In the part of our program we call the unittest.main function which will run the test for us.
We run the test by executing the file that we just created. Lets make our script executable and then run it.

chmod +x rearrange_test.py
./rearrange_test.py

It looks good and the output is very descriptive. It tells us how long it took our scripts to run, as well as the number test ran and whether or not the passed.

EDGE CASES
Our test so far has just one test case. We have to make it grow. Choosing test cases could be an exercise in creativity. Coming up with different ways a code might break can actually be super fun.
We will usually test that our code will work with the general case, but we will see what will happen when we give it input it might not run into on normal operations. For example, what happen in our function when we give it an empty string? Lets test for that and see.

#!/usr/bin/env python3

from rearrange import rearrange_name
import unittest

class TestRearrange(unittest.TestCase):
    def test_basic(self):
        testcase = "Lovelace, Ada"
        expected = "Ada Lovelace"
        self.assertEqual(rearrange_name(testcase), expected)

def test_empty(self):
    testcase = ""
    expected =""
    self.assertEqual(rearrange_name(testcase), expected)
    
unittest.main()

In the second method called test_empty() we are testing for an empty input string and see if it will return an empty output string. We check this behavior using the assertEqual function as well. 

./rearrange_test.py

We will see here that our test failed, because we have a problem with our code. 
Let us take a good look at the error message. The error tells that the test called test_empty failed and it failed with a TypeError, saying that 'NoneType' object isn't subscriptable. Interesting, because what we've considered here is an Edge case.
Edge Cases: Inputs to our code that produce unexpected results, and are found at the extreme ends of the range of input we imagine our program will typcially work with. Edge cases need special or particular handling in scripts in order for the code to continue to funtion properly.
In our rearranging example, we can handle this edge cases by performing a simple check of the result varialbe before operating with it. 

#!/usr/bin/env python3

import re

def rearrange_name(name):
    result = re.search(r"^([\w .]*), ([\w .]*)$", name)
    if result is None:
        return ""
    return "{} {}".format(result[2], result[1])

The if block accomplishes this for us. If we try to use an empty string, we will catch it with our check. What to return in an edge case is entirely upto you. In this case we want our code to return an empty string. Sometimes we might want our code to crash rather than it continuing. Other ways to handle edge cases is to return a 0, to a function that expects a numeber, negative numbers, or extremely large numbers. 
Lets run our code again and see if it passes.

./rearrange_test.py

Our test pass, We fixed the bug in our code, and by adding automatic test, we can make sure it wont happen again

ADDITIONAL TEST CASES
When we first handled this function, we came across spaces and dots that would make our regular expression not work, but we've fixed that already, but its still a good idea to add a test case to make sure that our code still works as we expect it to.
The last method in the class TestRearrange is used to illustrate if an extra initial and a dot would pass the test.

#!/usr/bin/env python3

from rearrange import rearrange_name
import unittest

class TestRearrange(unittest.TestCase):
    def test_basic(self):
        testcase = "Lovelace, Ada"
        expected = "Ada Lovelace"
        # Lets call the method assertEqual() on the instance of the class
        self.assertEqual(rearrange_name(testcase), expected)

    def test_empty(self):
        testcase = ""
        expected = ""
        # Lets call the method assertEqual() on the instance of the class
        self.assertEqual(rearrange_name(testcase), expected)

    def test_double_name(sefl):
        testcase = "Hopper, Grace M."
        expected = "Grace M. Hopper"
        self.assertEqual(rearrange_name(testcase), expected)

unittest.main()

Okay, that worked just fine, let us think of more creative ways to make our code fail. How about someone with only one name? 
The last method in the code below test for one name, with no comma in our string. We expect the result to be the same name provided to the function. Would this work?

#!/usr/bin/env python3

from rearrange import rearrange_name
import unittest

class TestRearrange(unittest.TestCase):
    def test_basic(self):
        testcase = "Lovelace, Ada"
        expected = "Ada Lovelace"
        # Lets call the method assertEqual() on the instance of the class
        self.assertEqual(rearrange_name(testcase), expected)

    def test_empty(self):
        testcase = ""
        expected = ""
        # Lets call the method assertEqual() on the instance of the class
        self.assertEqual(rearrange_name(testcase), expected)

    def test_double_name(self):
        testcase = "Hopper, Grace M."
        expected = "Grace M. Hopper"
        # Lets call the method assertEqual() on the instance of the class
        self.assertEqual(rearrange_name(testcase), expected)

    def test_one_name(self):
        testcase = "Voltaire"
        expected = "Voltaire"
        self.assertEqual(rearrange_name(testcase), expected)
        
unittest.main()

Woops! That did not work. The test output is slightly different than before. It shows the name of the test that failed, but now, instead of giving us a TypeError, it is giving us AssertionError, which means the original and expected values don't match. It does feel like our function returns an empty string instead of a real name. This is because there is a bug in our code.
When we checked if the result was none, we ruturned an empty string which caused our initial test to pass. Now we are passing a name that doesnt include a comma which makes our result variable None, and so the function returns an empty string.
We fix this by returning the originial name variable when the result is None.

#!/usr/bin/env python3

import re

def rearrange_name(name):
    result = re.search(r"^([\w .]*), ([\w .]*)$", name)
    if result is None:
        return name
    return "{} {}".format(result[2], result[1])

Now we run 

./rearrange_test.py

We fixed all the bugs and all our test pass.

BLACK BOX VS. WHITE BOX
One interesting concept in testing is knowing if our test is white box test or black box test.
White-box testing(AKA clear-box or transparent testing): Relies on the test creators knowledge of the software being tested to construct the test cases.
The white-box test creator knows how the code works and can write test cases that uses the understanding to make sure that everything is performing the way it is expected to.
Black box test, the software being tested is treated like an opeque box, in other words, the tester does not know the internals of how the software works. 
Black-box tests: Written with an awarness of what the program is supposed to do - its requirement or specifications - but not how it does it.
For example, a simple black-box test can to be verify that whenever you type www.google.de in your browser google search page, for germany is returned. You may not know how google server processed the request, but you know what the end result should be.
Both white-box and black-box test have thier own advantages.
White-box test are helpful because the test writer can use your knowledge of the source code to create test that covers most of the ways that the program behaves.
Black-box test are useful because the don't rely on the knowledge of how the system works. This means that your test cases are less likely to be biased by the code. They usually cover problems not anticipated by the programmer who wrote the scripts.
Also, not all test that we wrie needs to fall into one category or the other. We can write unit test that either white or black box, depending on which test methodolgy is choosen. 
If the unit test is created before any code is written based on specification on what the code is supposed to be doing, the could be considered black-box unit test. 
If unit test are written after the code is written or alongside the code, then test cases are made with the knowledge of how the code works, they are white box test.
Not everything is so black and white or binary. As an IT specialist, we need to test that software written by others behave in the way it is expected. To do this, we may use a combination of white-box and black-box test.
Lets say there's an online catlog of products that are sold by your company, you can have a black-box test that verifies that the details for a product are displayed when you open the page for a specific product.
Apart from that, we can have white box test that calls different functions used by that page checking that the prices are displayed in the right currency, that the description is correctly wrapped and so on.

OTHER TEST TYPES
At the other end of unit test which simply checks that single function or method is functioning properly regardless of the enviroment, is the Intergration test.
Intergration test verifies that the interaction between various piece of code in an intergrated enviroments are walking the way we expect them to. 
While unit test should not cross boundaries like make a network request, or integrate with the API or database, the goal of the integration test is to verify that this interactions and the whole system works the way you expect it to.
Intergration test usually takes the modules or unit code that the unit test verifies then combine them into a group to test.
Depending on what our program does and how it interacts with the rest of the systems involved, we might need to create a seperate test enviroment for the test which runs a test version of the software we are trying to verify.
We might be able to run our test against the actual version of our system that is running, but that is only if our code makes no changes to the production enviroment. 
This test takes a bit more work to set up because we have to be sure that we have the test version of all relevant systems. But it might help issues that unit test cannot detect, so the extra stress is actually worth it.
For example, if the service we are trying to test interacts with a database, we might want to set up a seperate test database with a test user and test tables .This lets you run all the test you need in an enviroment you can control without risking modifying the production database. THE VARIANT OF UNIT TEST ARE REGRESSION TESTS. THEY'RE USUALLY WRITTEN AS PART OF THE DEBUGGING AND TROUBLESHOOTING PROCESS TO VERIFY THAT AN ISSUE OR PROBLEM HAS BEEN FIXED ONCE IT HAS BEEN IDENTIFIED. 
Say our script has a bug and we are trying to fix it, a good approach is to first run a test that fails by triggering its buggy behavior, then fix the bug so that the test passses.
Regression test are a usual part of the test suite because the ensure that the same mistake does not happen twice. The same bug cannot be reintrodued in the code because introducing it will cause the regression test to fail.
Smoke tests (AKA Build verification tests) comes from a concept that originated from testing hardware equipment. Plug in a given equipment and see if smokes are comming out of it.
In writing software, smoke test serves as a kind of sanity check to find major bugs in a program.
Smoke test answer basic questions like: does the program run?
This test are usually run before more refined testing takes place, since if the software fails the smoke test we can be sure that none of the other test would pass either.
For a web service, smoke test would be to test whether there is a service running on the correponding port.
For automation script, smoke test would be to run it manually with some basic input and check that the script finishes succesfully. 
Load test is another type of test. This ensures that the system bahaves well when it is under significant load. To perform this test, we would have to generate traffic to our application simulating typical usage of the service. 
This test is helpful when employing new versions of our application to verify that performance does not degrade.
For example, we might want to measure the response time of our website while there are 100 request per second on our pages or 1,000 or 10,000. The actual number would depend on the expecation of how much traffic our website would. recieve.
Taken together, a group of test of one or many kinds is usually refered to as a test suite. 
A good diversity of test types may help create a more roburst test suite that ensures that your script and automation do what you tell them to.

TEST DRIVEN DEVELOPMENT (TDD)
We might recall the most test occurs after the code has been written, This seems like a natural progression, first, you write your script, then you write test that verifies the scripts does what you want it to do. But this is not always the best approach.
A process called test driven approach or (TDD) call for creating the test before writing the code. This might seem a bit counter intuitive, but it help to create more thoughtfull, well written programs. When we first create test, it shows we've thought about the problem that we want to solve, and some different approaches we might use to accomplish it. 
Writing a test first also helps think about the ways our programs can fail or break, which could lead to some valuable insight and change the approach you take for the better. 
The test driven cycle usually follows the process of: writing a test then running it to make sure it fails, after all we haven't written the code to make it pass yet. Once we've verified that it fails, we write a code that will satisfy the test and run the test again, if it passes, we can continue to the next part of our program. If it fails, we debug and run the test again.
This cycle is repeated for each new feature of your script, until your script is up running.
REMEMBER THAT GOOD TESTING MAKES ANY AUTOMATION SCRIPT YOU WRITE MORE ROBURST, RESILIENT AND LESS BUGGY.
Many companies take testing a step further, combining it with version control systems and development processes.
When engineers submit their code, it is integrated into the main repo and test are automatically run against it to spot bugs and errors in a process called 'continous integration.'
Setting up a continous integration process can be a big undertaking. 

THE TRY EXCEPT CONSTRUCT
We have so far seen examples of TypeError, IndexError, ValueError, etc. Up until now, we have been modifying our code whenever we encounter errors, because whenever this errors occur the program stops, and we dont want our program to stop before the finish their work.
Sometimes, it is easier to make a verification with a conditional to avoid the error as we did in our rearrange example where we checked if the result from our regex search was None, and did something different in that case.
Othertimes, so many things could go wrong that checking for all of them becomes challenging.
Say we had a function that open a file and did some processes on it, what if the file doesn't exist? What if the user doesn't have the permission to read the file? Or, what if the file is locked by a different process and couldn't be open right now? We could check for all this things, but what if there is another problem that causes the open function to raise and error? In cases like this, the best approach is to use a try-except construct. Let's see this in action in an example. 

characters.py
#!/usr/bin/env python3

def character_frequency(filename):
    """Counts the frequency of each character in the given file"""
    # First try to open the filename
    try:
        f = open(filename)
    except OSError:
        return None

    # Now process the filename
    characters = {}
    for line f:
        for char in line:
            characters[char] = characters.get(char, 0) + 1
    f.close()
    return characters
    
The code above will count the frequency of chatacters in a file. To do that the first step is to open the file. In this function, we put the call to the open function inside the try and except block.
In this example we try to perform the action that we want in the try block. If there's an error, it goes into the except part of the block that matches the error and does whatever cleanup is neccessary. 
Here, we have just one except block for the OSError error type, but there could be more except blocks to capture more errors. 
So, when writing a try and exceot block, the important thing to remember is that: The code in the except block is only executed if one of the instruction in the try block raises an error of the matching type. In this case, in the except block we are returning None which indicates that the function was not able to do what was requested of it.
Its not just returning None that we could return in the except block, we could also set some base value like 0 for numbers, empy string for string, empty list for list, etc. It all depends on what our function does and what we need to get done.
THE IMPORTANT POINT IS THAT WHEN WE HAVE AN OPERATION THAT RAISES AN ERROR, WE ALWAYS WANT TO HANDLE THAT FAILURE GRACEFULLY BY USING THE TRY AND EXCEPT BLOCK. 
TO USE A TRY AND EXCEPT BLOCK, WE HAVE TO BE AWARE OF THE ERRORS A FUNCTION MIGHT RAISE. THIS INFO IS USUALLY PART OF THE DOCUMENTATION OF THE FUNCTION. once we know this, we put operations that might raise an error as part of the try block, and the actions to take when errors are made as part of the except block.

RAISING ERRORS
We have looked into how to handle errors when they are raised by the function that we call. In some cases we might want to raise the erros ourselves. THIS USUALLY HAPPENS WHEN SOME OF THE CONDITIONS NECCESSARY FOR OUR FUNCTIONS TO DO ITS JOB PROPERLY AREN'T MET, AND RETURNING NONE OR SOME ORDER BASE VALUE ISN'T ENOUGH. 
For example, say we had a function, that verifies whether a chosen username is valid, one of the checks this function does is verify that the provided name is at least a certain amount of characters, with the minimum value recieved by a prameter something like this:

#!/usr/bin/env python3

def validate_user(username, minlen):
    if len(username) < minlen:
        return False
    if not username.isalnum():
        return False
    return True

In this function, we are first checking that the username has at least minlen characters. then we check if there are any none alpha-numeric characters in the string which is another critaria for validating a username. If all the checks pass, we return True to indicate the the username is valid.
This code works as long as the provided values are sensible. what will happen if the minlen value is 0 or -ve? Then our function will allow an empty user name as valide which doesn't make sense.
To prevent this from happening we can add an extra check to our function which will verify that recieved parameters are sane. In this case, returning False will be misleading because its not that the username is invalid, but that the minlen value does not make sense. 
Lets add a check to verify that minlen is at least 1 and raise an error if that is not the case. THE KEY WORD TO GENERATE AN ERROR IN PYTHON IS 'raise'.

#!/usr/bin/env python3

def validate_user(username, minlen):
    if minlen < 1:
        raise ValueError("minlen must be at least 1")
    if len(username) < minlen:
        return False
    if not username.isalnum():
        return False
    return True

We could raise errors with the standard errors Python provides for us, or we could create our own errors if they're not good enough for us. 
In this case we are raising a ValueError, which indicates that there was an error with one of the values of the parameters.
Lets try out the code in the interpreter.

python3

from validations import validate_user
validate_user("", -1)

It returns a ValueError as we wanted it to. Lets also try calling it with valid parameters to see if those will work as well.

validate_user("", 1)

validate_user("myuser", 1)

The both work. What if we try to parse something as a username other than a string? Lets try a few example. Lets try a number.

validate_user(88, 1)

This fails because the int type has no len() function. Lets try an empty list

validate_user([], 1)

Because this list is shorter than the minimum length, our code returns False. Lets now try it with a list of one element.

validate_user(["name"], 1)

The function returns an error wchich tells us that 'isalnum' is not an attribute of a 'list'.
It is usually the responsibility of whoever is calling the function to call it with the right parameters. But in some cases, we might want to do it explicitly by checking that we are recieving a value that make sense to that function. So lets checkout an alternative to the raise keyword that we can use for situtions when we want to check that our code behaves the way it should, particularly when we want to avoid situation that should never happen. This is the 'assert' key word. This tries to verify that a conditional statement is True, and if it is False, it raises an AssertionError.
Lets add an assertion to our function.

#!/usr/bin/env python3

def validate_user(username, minlen):
    assert type(username) == str, "username must be a string"
    if minlen < 1:
        raise ValueError('minlen must be at least 1')
    if len(username) < minlen:
        return False
    if not username.isalnum():
        return False
    return True

We have added an assertion which verifies that the type of the username variable is 'str', which we know is the name the interpreter uses for strings.
If the function is called with a username parameter that is not a string, an error would be raised with the message we provided.
We would need to close our interpreter and restart it to be able to import the updated module.
Let us now call our function with something that is not a string.

from validations import validate_user
validate_user(["name"], 1)

An assertion error is raised, telling the user that username must be a string.
WE USUALLY DONT NEED TO CHECK THE TYPES OF OUR PARAMETERS. DEPENDING ON WHAT OUR FUNCTIONS DOES, IT MUGHT BE PERFECTLY OK TO ALLOW SCRIPTS CALL IT WITH PARAMETERS OF DIFFERENT TYPES. 
ASSERTIONS CAN BE SUPER HELPFUL IF WE ARE DEBUGGING SOME CODE THAT IS NOT BEHAVING THE WAY WE EXPECT IT TO. WE CAN ADD IT AT ANY POINT WHERE WE WANT TO ENSURE THAT THE VARIABLES CONTAINS THE VALUES AND TYPES THAT IT SHOULD or when we think that something that should'nt happen is happening.
ASSERTION WOULD BE REMOVED FROM OUR CODE IF WE ASK THE INTERPRETER TO OPTIMISE IT TO MOVE FASTER. SO AS A RULE, WE SHOULD USE 'raise' TO CHECK FOR CONDITIONS THAT WE EXPECT TO HAPPEN DURING NORMAL EXECUTION OF OUR CODE, AND 'assert' TO VERIFY SITUATIONS THAT ARE UNXPECTED BUT MIGHT CAUSE A CODE TO MISBEHAVE.

TESTING FOR EXPECTED ERRORS
From the previous example we did testing for edge cases, the expectation is that the fucntion would raise an error, and we want to test that too(i.e, we know that the function should raise an error, but we want to make sure that it does raise and error by testing it). To do this, we use the assertRaises method provided by the unittest module. 
Lets test this out by adding a lot of test cases in the test suite for our validation_user function

import unittest

from validations import validate_user

class TestValidateUser (unittest.TestCase):
    def test_valid(self):
        self.assertEqual(validate_user("validuser", 3), True)

    def test_too_short(self):
        self.assertEqual(validate_user("inv", 5), False)

    def test_invalid_characters(self):
        self.assertEqual(validate_user("invalid_user", 1), False)

unittest.main()

This is the test suite above, we have a few test case to check that the function above is working when it recieves sane parameters. 
We now want to add test cases for when it recieves parameters that dont make sense, like a negative value for minlen or a username that is a list, instead of a string.

import unittest

from validations import validate_user

class TestValidateUser (unittest.TestCase):
    def test_valid(self):
        self.assertEqual(validate_user("validuser", 3), True)

    def test_too_short(self):
        self.assertEqual(validate_user("inv", 5), False)

    def test_invalid_characters(self):
        self.assertEqual(validate_user("invalid_user", 1), False)

    def test_invalid_minlen(self):
        self.assertRaises(ValueError, validate_user, "user", -1)
# Run the tests
unittest.main()

The assertRaises method works a little differently from the assertEqual method. In this case, we need to first pass the error that we expect the function to raise, then the function name followed by any parameter that needs to be passed to that function ("user", -1)
BEHIND THE SCENES, THIS FUNCTION (assertRaises) IS CALLING THE FUNCTION THAT WE WANT TO TEST USING THE TRY-EXCEPT BLOCK, CHECKING THAT IT DOES RAISE THE ERROR IT IS EXPECTED TO RAISE. Lets run the test suite and verify that our code works correctly

chmod +x validations_test.py
./validations_test.py

The code ran succesfully.

WEEK 5 ASSIGNMENT: EXTERNAL GRADED TOOLS: IMPLEMENTING UNIT TESTING

Prerequisites
First, you need to find the .csv file called user_emails.csv, which contains user names and their respective email addresses within the data directory. Navigate to this directory using the following command:

cd ~/data
Copied!
List the files using the following command:

ls
Copied!
You should now see a file named user_emails.csv. To view the contents of the user_emails.csv file, enter the following command:

cat user_emails.csv
Copied!
Your IT coworker has also left a script named emails.py within the scripts directory.

Use the following command to navigate to the scripts directory:

cd ~/scripts
Copied!
Now list the contents within the scripts directory using the following command:

ls
Copied!
Here, you will find the script named emails.py. This script aims to match users to their respective email addresses.

You can view the file using the following command:

cat emails.py
Copied!
This script consists of two functions: populate_dictionary(filename) and find_email(argv). The function populate_dictionary(filename) reads the user_emails.csv file and populates a dictionary with name/value pairs. The other function, find_emails(argv), searches the dictionary created in the previous function for the user name passed to the function as a parameter. It then returns the associated email address. This script accepts employee's first name and last name as command-line arguments and outputs their email address.

The script accepts arguments through the command line. These arguments are stored in a list named sys.argv. The first element of this list, i.e. argv[0], is always the name of the file being executed. So the parameters, i.e., first name and last name, are then stored in argv[1] and argv[2] respectively.

Let's test the script now.

Since you know the contents of the user_emails.csv file, choose any name to be passed as a parameter, or you can use the following name:

python3 emails.py Blossom Gill
Copied!
This will give you the email address associated with the Full Name passed as parameters. In this case, the name is Blossom Gill and the email ID associated with this name is blossom@abc.edu.

f266d9bee9b399bf.png

That was simple and straightforward. But this script has few bugs. In the next part of this lab, we will design some test cases and correct the bugs in the script.

Introduction to test cases
Writing a test encourages you to think through the script's design and goals before writing the code. This keeps you focused and lets you create better designs. If you learn how to easily test your scripts, you'll be able to create code that's better defined and cohesive.

In this lab, we will write tests and correct bugs within the existing script.

In this section, we will write a basic test case and see how it works. A test case is an individual unit of testing that checks for a specific response to a particular set of inputs.

Use the following command to create a new file (in scripts directory) to write our test cases:

nano ~/scripts/emails_test.py
Copied!
The file should now open in edit mode. This script's primary objective is to write test cases that correct bugs in the existing emails.py script. We will use the unittest package for this.

Add the following shebang line and import the necessary packages:

#!/usr/bin/env python3
import unittest
Copied!
The package unittest supports test automation, sharing of setup and shutdown code for tests, aggregation of tests into collections, and independence of the tests from the reporting framework. This module also provides classes that make it simple to support these qualities for a set of tests.

The following import statement allows a Python file to access the script from another Python file. In this case, we will import the function find_email, which is defined in the script emails.py.

from emails import find_email
Copied!
Now let's create a class:

class EmailsTest(unittest.TestCase):
Copied!
Classes are a way to bundle data and functionality together. Creating a new class creates a new type of object, which further allows new instances of that type to be made.

Another important aspect of the unittest module is the test runner. A test runner is a component that orchestrates the execution of tests and provides the outcome to the user.

A test case is created by subclassing unittest.TestCase. Let's write our first basic test case, test_basic.

  def test_basic(self):
    testcase = [None, "Bree", "Campbell"]
    expected = "breee@abc.edu"
    self.assertEqual(find_email(testcase), expected)
if __name__ == '__main__':
  unittest.main()
Copied!
Here, variable test case contains the parameters to be passed to the script emails.py. As we mentioned, the script file is the first element of input parameters through command line using argv. Since we already imported the function find_email from emails.py earlier, we will pass None in place of the script file and call it later in the script. Adding to None, we will pass a first name and last name as parameters.

The variable stores the expected value to be returned by emails.py. The method assertEqual passes the test case to the function find_email, which we imported earlier from emails.py, and checks whether it generates the expected output.

Save the file by clicking Ctrl-o, Enter key, and Ctrl-x.

We will run this file through the command line here. To do this, we will give the file permissions for execution.

chmod +x emails_test.py
Copied!
Now, let's run our first test case using the following command:

./emails_test.py
Copied!
The output shows the number of tests run and its associated output.

45050237c2d0e1db.png

The test case passed. This was a basic test case to show how test cases with Python work. In the next section, we will write a few more test cases covering other possibilities.

Test Case 1: Missing parameters
Imagine a scenario where the user doesn't give either their first name or last name. What do you think the output would be in this case?

Lets try this out. Choose any first or last name of your choice or use the following name to be passed to emails.py as a parameter:

python3 emails.py Kirk
Copied!
2c9abfdcbc154cc.png

This now gives us an error. The script doesn't take just one parameter as input and so it produces an error.

Let's now write a test case to handle this type of error. This test case should pass just the first name to the script.

nano emails_test.py
Copied!
Add the test case test_one_name just after the first test case.

Pro tip: Note down the name of the test cases. Knowing the names will be helpful in running individual tests.

  def test_one_name(self):
    testcase = [None, "John"]
    expected = "Missing parameters"
    self.assertEqual(find_email(testcase), expected)
Copied!
The file emails_test.py should now look like this:

#!/usr/bin/env python3
import unittest
from emails import find_email
class TestFile(unittest.TestCase):
  def test_basic(self):
    testcase = [None, "Bree", "Campbell"]
    expected = "breee@abc.edu"
    self.assertEqual(find_email(testcase), expected)
  def test_one_name(self):
    testcase = [None, "John"]
    expected = "Missing parameters"
    self.assertEqual(find_email(testcase), expected)
if __name__ == '__main__':
  unittest.main()
Copied!
Save the file by clicking Ctrl-o, Enter key, and Ctrl-x.

Now run the second test using the following command:

./emails_test.py
Copied!
Another way to run a particular function within the script is to specify the class name and the function name you want to run. This helps us run individual tests without having to run all the test cases in the test script again.

This now returns the following output:

Test case two fail

The output shows the function that caused the error and the description related to the error. It returned IndexError, which is raised while attempting to access an index that's outside the bounds of a list. This error occurs because the script emails.py takes in two parameters, the first and last name. We need to handle this type of incomplete inputs within the script. We need to decide what the correct output should be. Let's say, in this case, your script should output "Missing parameter".

Let's now fix the code. The last test case showed that the script fails if only one parameter is passed. We would now handle these types of incomplete inputs given to the script file emails.py.

There are two ways to solve this issue:

Use a try/except clause to handle IndexError.
Check the length of input parameters before traversing the user_emails.csv file for the email address.
You can use either of the above methods, but remember that test cases should pass and the script should return "Missing parameters" in this case.

We will use the try/except clause here to solve this issue. Try/except blocks are used for exceptions and error handling. Since exceptions are detected during execution of a script/program, error handling in Python is done using exceptions that are caught in try blocks and handled in except blocks.

Let's dive into how try/except blocks work:

First, we execute the try clause.
If no exception occurs, the except clause is ignored.
If an exception occurs during the execution of the try clause, the rest of the try clause is then skipped.
It then attempts to match the type with the exception named after the except keyword. If this matches, the except clause is executed. If it doesn't, the control is passed on to outer try statements. If no handler is found, it's an unhandled exception and the execution stops with an error message.
A try statement may have more than one except clause to specify handlers for different exceptions. In our case, the exception error we need to handle is IndexError.

Let's move forward by adding a try/except clause to the script emails.py.

nano emails.py
Copied!
We will add the complete code block within the function find_email(argv), which is within the try block, and add an IndexError exception within the except block. This means that the execution will start normally with any number of parameters given to the script. If the function find_email(argv) receives the required number of parameters, it will return the email address. And if the function doesn't receive the required number of parameters, it will throw an IndexError exception and the except clause which handles IndexError exception would then execute.

Add the body of the function find_emails(argv) within the try block and add an except block:

def find_email(argv):
  """ Return an email address based on the username given."""
  # Create the username based on the command line input.
  try:
    fullname = str(argv[1] + " " + argv[2])
    # Preprocess the data
    email_dict = populate_dictionary('/home/<username>/data/user_emails.csv')
    # Find and print the email
    return email_dict.get(fullname.lower())
  except IndexError:
    return "Missing parameters"
Copied!
The complete file emails.py should now look like this:

#!/usr/bin/env python3
import sys
import csv
def populate_dictionary(filename):
  """Populate a dictionary with name/email pairs for easy lookup."""
  email_dict = {}
  with open(filename) as csvfile:
    lines = csv.reader(csvfile, delimiter = ',')
    for row in lines:
      name = str(row[0].lower())
      email_dict[name] = row[1]
  return email_dict
def find_email(argv):
  """ Return an email address based on the username given."""
  # Create the username based on the command line input.
  try:
    fullname = str(argv[1] + " " + argv[2])
    # Preprocess the data
    email_dict = populate_dictionary('/home/{{ username }}/data/user_emails.csv')
    # Find and print the email
    return email_dict.get(fullname.lower())
  except IndexError:
    return "Missing parameters"
def main():
  print(find_email(sys.argv))
if __name__ == "__main__":
  main()
Copied!
Save the file by clicking Ctrl-o, Enter key, and Ctrl-x.

Now run the test cases within the file email_test.py again:

./emails_test.py
Copied!
You should now see that both the test cases ran successfully and an OK message appeared.